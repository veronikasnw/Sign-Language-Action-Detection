# Sign-Language-Action-Detection
This Repository contains Jupiter notebooks created during the Final Project phase of the Bootcamp at WBS Coding School, Germany (May 2024).
The Final has been developed by my team and myself - Christian, Martin and Veronnika.

## Overview of the project
The main idea of the project is to train a model which will facilitate and improve the quality of communication between people who use a sign language as their mmain means of comminication.
Our aim is to make these people more independent when it comes to communicating with public administration, health care services, including educational, social, and occupational levels.

## Steps our team has taken
We wanted to create a model which will detect a sign from real-time video session and transform the data into written words. For this goal, we decided to use an action-detecting model instead of object-detecting one, since sign languages consist of dynamic compination of movements and not of static postures.

